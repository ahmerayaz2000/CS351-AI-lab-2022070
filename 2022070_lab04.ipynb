{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNm9AJkAF2DwsKFiSr0UfPh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmerayaz2000/CS351-AI-lab-2022070/blob/main/2022070_lab04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYaVwOVN7GlU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "titanic_data = pd.read_csv(url)\n",
        "\n",
        "# Display the first few rows\n",
        "print(titanic_data.head())\n",
        "\n",
        "# Visualizing the distribution of key features\n",
        "sns.countplot(x='Pclass', data=titanic_data)\n",
        "plt.title('Passenger Class Distribution')\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(titanic_data['Age'].dropna(), bins=30, kde=True)\n",
        "plt.title('Age Distribution')\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='Sex', data=titanic_data)\n",
        "plt.title('Gender Distribution')\n",
        "plt.show()\n",
        "\n",
        "# Check for missing values\n",
        "print(titanic_data.isnull().sum())\n",
        "\n",
        "# Handle missing values\n",
        "titanic_data['Age'].fillna(titanic_data['Age'].median(), inplace=True)\n",
        "titanic_data['Embarked'].fillna(titanic_data['Embarked'].mode()[0], inplace=True)\n",
        "titanic_data.drop(['Cabin'], axis=1, inplace=True)\n",
        "\n",
        "# Encode categorical variables\n",
        "titanic_data['Sex'] = titanic_data['Sex'].map({'male': 0, 'female': 1})\n",
        "titanic_data = pd.get_dummies(titanic_data, columns=['Embarked'], drop_first=True)\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "titanic_data[['Age', 'Fare']] = scaler.fit_transform(titanic_data[['Age', 'Fare']])\n",
        "\n",
        "# Split the dataset into features and target variable\n",
        "X = titanic_data.drop(['Survived', 'Name', 'Ticket', 'PassengerId'], axis=1)\n",
        "y = titanic_data['Survived']\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Implementing k-NN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Implementing Decision Tree\n",
        "dtree = DecisionTreeClassifier()\n",
        "dtree.fit(X_train, y_train)\n",
        "\n",
        "# k-NN Predictions\n",
        "knn_predictions = knn.predict(X_test)\n",
        "\n",
        "# Decision Tree Predictions\n",
        "dtree_predictions = dtree.predict(X_test)\n",
        "\n",
        "# Evaluate k-NN\n",
        "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
        "knn_precision = precision_score(y_test, knn_predictions)\n",
        "knn_recall = recall_score(y_test, knn_predictions)\n",
        "knn_f1 = f1_score(y_test, knn_predictions)\n",
        "\n",
        "# Evaluate Decision Tree\n",
        "dtree_accuracy = accuracy_score(y_test, dtree_predictions)\n",
        "dtree_precision = precision_score(y_test, dtree_predictions)\n",
        "dtree_recall = recall_score(y_test, dtree_predictions)\n",
        "dtree_f1 = f1_score(y_test, dtree_predictions)\n",
        "\n",
        "# Print the results\n",
        "print(\"k-NN Performance:\")\n",
        "print(f\"Accuracy: {knn_accuracy:.2f}, Precision: {knn_precision:.2f}, Recall: {knn_recall:.2f}, F1 Score: {knn_f1:.2f}\")\n",
        "\n",
        "print(\"\\nDecision Tree Performance:\")\n",
        "print(f\"Accuracy: {dtree_accuracy:.2f}, Precision: {dtree_precision:.2f}, Recall: {dtree_recall:.2f}, F1 Score: {dtree_f1:.2f}\")\n",
        "\n",
        "# For visualization, we will use 'Pclass' and 'Sex'\n",
        "X_viz = titanic_data[['Pclass', 'Sex']]\n",
        "y_viz = titanic_data['Survived']\n",
        "\n",
        "# Create a meshgrid for visualization\n",
        "x_min, x_max = X_viz['Pclass'].min() - 1, X_viz['Pclass'].max() + 1\n",
        "y_min, y_max = X_viz['Sex'].min() - 1, X_viz['Sex'].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "\n",
        "# Plot decision boundaries for k-NN\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "Z_knn = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z_knn = Z_knn.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z_knn, alpha=0.3)\n",
        "plt.scatter(X_viz['Pclass'], X_viz['Sex'], c=y_viz, edgecolors='k', marker='o')\n",
        "plt.title('k-NN Decision Boundary')\n",
        "plt.xlabel('Pclass')\n",
        "plt.ylabel('Sex')\n",
        "\n",
        "# Plot decision boundaries for Decision Tree\n",
        "plt.subplot(1, 2, 2)\n",
        "Z_dtree = dtree.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z_dtree = Z_dtree.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z_dtree, alpha=0.3)\n",
        "plt.scatter(X_viz['Pclass'], X_viz['Sex'], c=y_viz, edgecolors='k', marker='o')\n",
        "plt.title('Decision Tree Decision Boundary')\n",
        "plt.xlabel('Pclass')\n",
        "plt.ylabel('Sex')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Performance metrics visualization\n",
        "labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "knn_scores = [knn_accuracy, knn_precision, knn_recall, knn_f1]\n",
        "dtree_scores = [dtree_accuracy, dtree_precision, dtree_recall, dtree_f1]\n",
        "\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bar_width = 0.35\n",
        "rects1 = ax.bar(x - bar_width/2, knn_scores, bar_width, label='k-NN')\n",
        "rects2 = ax.bar(x + bar_width/2, dtree_scores, bar_width, label='Decision Tree')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_title('Model Performance Comparison')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mys6Q4U37HeG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}